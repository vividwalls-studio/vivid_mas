version: '3.8'

services:
  crawl4ai:
    image: unclecode/crawl4ai:latest
    container_name: crawl4ai
    restart: unless-stopped
    ports:
      - "11235:11235"
    shm_size: 1g
    environment:
      - INSTALL_TYPE=default
      - ENABLE_GPU=false
    volumes:
      - ./shared:/data/shared
      - ./.llm.env:/app/.llm.env:ro
    networks:
      - vivid_mas
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11235/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  vivid_mas:
    external: true